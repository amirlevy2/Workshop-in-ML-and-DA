{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616d1518",
   "metadata": {
    "papermill": {
     "duration": 0.004571,
     "end_time": "2024-11-12T05:58:56.576360",
     "exception": false,
     "start_time": "2024-11-12T05:58:56.571789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Import packages for training KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefe6c0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:58:56.586418Z",
     "iopub.status.busy": "2024-11-12T05:58:56.585976Z",
     "iopub.status.idle": "2024-11-12T05:59:13.788170Z",
     "shell.execute_reply": "2024-11-12T05:59:13.786738Z"
    },
    "papermill": {
     "duration": 17.210184,
     "end_time": "2024-11-12T05:59:13.790768",
     "exception": false,
     "start_time": "2024-11-12T05:58:56.580584",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4591cf8",
   "metadata": {
    "papermill": {
     "duration": 0.003841,
     "end_time": "2024-11-12T05:59:13.798818",
     "exception": false,
     "start_time": "2024-11-12T05:59:13.794977",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Load data with or without varinced columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2ae659",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:13.808951Z",
     "iopub.status.busy": "2024-11-12T05:59:13.808251Z",
     "iopub.status.idle": "2024-11-12T05:59:14.035365Z",
     "shell.execute_reply": "2024-11-12T05:59:14.034181Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.235019,
     "end_time": "2024-11-12T05:59:14.037896",
     "exception": false,
     "start_time": "2024-11-12T05:59:13.802877",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load(per = 0, isVar = False):\n",
    "    df = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/train.csv')\n",
    "    \n",
    "    df.drop('Id', axis=1, inplace=True)\n",
    "    \n",
    "    train_df = df.drop('Class', axis=1)\n",
    "    \n",
    "    test_df = df['Class']\n",
    "    \n",
    "    # map A to 0 B to 1 - will also try use other numbers or ignore this column\n",
    "    train_df['EJ'] = train_df['EJ'].map({'A': 0, 'B': 1})\n",
    "    \n",
    "    # replace null values with the mean of the column\n",
    "    train_df.fillna(train_df.mean(), inplace=True)\n",
    "    \n",
    "    # remove top 'per' varianced columns\n",
    "    def remove_var(X_train, isVar, per = 0.1):\n",
    "        # Calculate the variance of each column\n",
    "        variances = X_train.var()\n",
    "        \n",
    "        # Sort variances in descending order and select the top 20% most variable columns\n",
    "        top_var = int(len(variances) * per)\n",
    "        high_variance_columns = variances.nlargest(top_var).index\n",
    "        # print(\"HELP. PER = \", per, \" ISVAR\", isVar)\n",
    "        if not isVar:\n",
    "            # Drop these high variance columns from the train_df\n",
    "            X_train.drop(columns=high_variance_columns, inplace=True)\n",
    "        else: \n",
    "            X_train = X_train[high_variance_columns]\n",
    "        \n",
    "        return X_train, high_variance_columns\n",
    "    if per == 0: return train_df, test_df, None\n",
    "        \n",
    "    train_df, high_variance_columns = remove_var(train_df, isVar, per)\n",
    "    return train_df, test_df, high_variance_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8348fbf",
   "metadata": {
    "papermill": {
     "duration": 0.004276,
     "end_time": "2024-11-12T05:59:14.046428",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.042152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Helper Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9786e07d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:14.056991Z",
     "iopub.status.busy": "2024-11-12T05:59:14.056522Z",
     "iopub.status.idle": "2024-11-12T05:59:14.066997Z",
     "shell.execute_reply": "2024-11-12T05:59:14.065389Z"
    },
    "papermill": {
     "duration": 0.019032,
     "end_time": "2024-11-12T05:59:14.069649",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.050617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# KNN function to return probability for class 1\n",
    "def k_NN(data, labels, k, testData):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(data, labels)\n",
    "    return knn.predict_proba(testData)[:, 1]\n",
    "\n",
    "# Calculate average probabilities across multiple KNN models\n",
    "def getResult(max_k, x_train, y_train, x_test):\n",
    "    arrays = [k_NN(x_train, y_train, i, x_test) for i in range(3, max_k + 1, 1)]  # KNN for odd k values\n",
    "    return np.mean(np.stack(arrays), axis=0)  # Average across all models\n",
    "\n",
    "# Convert probabilities to class predictions (0 or 1)\n",
    "def getClassesResult(max_k, x_train, y_train, x_test):\n",
    "    return np.where(getResult(max_k, x_train, y_train, x_test) >= 0.5, 1, 0)\n",
    "\n",
    "# Generate final DataFrame with probabilities for both classes\n",
    "def final_sub(max_k, x_train, y_train, x_test, ids):\n",
    "    class_1 = getResult(max_k, x_train, y_train, x_test)\n",
    "    class_0 = 1 - class_1\n",
    "    return pd.DataFrame({'Id': ids, 'class_0': class_0, 'class_1': class_1})\n",
    "\n",
    "# Calculate percentage of equal elements between two arrays\n",
    "def percentage_equal(arr1, arr2):\n",
    "    return (np.sum(arr1 == arr2) / arr1.size) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c47be6",
   "metadata": {
    "papermill": {
     "duration": 0.004249,
     "end_time": "2024-11-12T05:59:14.078212",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.073963",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Main function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4db3cb9",
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:14.089148Z",
     "iopub.status.busy": "2024-11-12T05:59:14.087971Z",
     "iopub.status.idle": "2024-11-12T05:59:14.100862Z",
     "shell.execute_reply": "2024-11-12T05:59:14.099637Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.021161,
     "end_time": "2024-11-12T05:59:14.103583",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.082422",
     "status": "completed"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_vs_i(train_df, test_df, message):\n",
    "    \"\"\"\n",
    "    Function to plot accuracy vs i values for different KNN models.\n",
    "\n",
    "    Parameters:\n",
    "    train_df (DataFrame): Training data features.\n",
    "    test_df (DataFrame): Test data features.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_df, test_df, test_size=0.2, random_state=4)\n",
    "    X_train_rows = [row.to_numpy() for _, row in X_train.iterrows()]\n",
    "    X_test_rows = [row.to_numpy() for _, row in X_test.iterrows()]\n",
    "\n",
    "    # Initialize lists for storing i values and accuracies\n",
    "    i_values, accuracies = [], []\n",
    "\n",
    "    # Loop through odd values of i\n",
    "    for i in range(3, 76,1):\n",
    "        y_pred = getClassesResult(i, X_train_rows, y_train, X_test_rows)\n",
    "        accuracy = percentage_equal(y_pred, y_test)\n",
    "        i_values.append(i)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    j , acc = i_values[np.argmax(accuracies)], np.max(accuracies)\n",
    "    # Plot the results\n",
    "    # plt.plot(i_values, accuracies, linestyle='-', color='b')\n",
    "    # plt.xlabel('i values')\n",
    "    # plt.ylabel('Test Accuracy')\n",
    "    # plt.title('Accuracy vs i')\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    #print(f\"{message} Best i is: {j} with acc of: {acc:.3f}\")\n",
    "    return j , acc\n",
    "\n",
    "def run_diff_var():\n",
    "    def run(isVar, mes):\n",
    "        i_values, accuracies = [], []\n",
    "        for i in np.arange(0.05, 1, 0.05):\n",
    "            percentage = round(i * 100, 3)\n",
    "            message_with_percent = f\"{mes} at {percentage}% varianced columns\"\n",
    "            # Call your load function with the appropriate parameters\n",
    "            x, y, _ = load(per=i, isVar=isVar)  \n",
    "            j,accuracy = plot_accuracy_vs_i(x, y, message_with_percent)\n",
    "            i_values.append((i,j))\n",
    "            accuracies.append(accuracy)\n",
    "        print(f\"Best (per, K) is: {i_values[np.argmax(accuracies)]} with acc of: {np.max(accuracies):.3f}\")\n",
    "\n",
    "    run(True, \"Using variance    \")  # Message when variance is used\n",
    "    run(False, \"Not using variance\")  # Message when variance is not used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dea73eb",
   "metadata": {
    "papermill": {
     "duration": 0.003845,
     "end_time": "2024-11-12T05:59:14.112769",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.108924",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Run Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2500247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:14.122721Z",
     "iopub.status.busy": "2024-11-12T05:59:14.122292Z",
     "iopub.status.idle": "2024-11-12T05:59:14.127193Z",
     "shell.execute_reply": "2024-11-12T05:59:14.126005Z"
    },
    "papermill": {
     "duration": 0.012746,
     "end_time": "2024-11-12T05:59:14.129619",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.116873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# x, y, _ = load()  # Load without any variance\n",
    "# plot_accuracy_vs_i(x, y, \"No variance applied\")\n",
    "# run_diff_var()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93e98f",
   "metadata": {
    "papermill": {
     "duration": 0.00391,
     "end_time": "2024-11-12T05:59:14.137716",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.133806",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**best: remove 0.89 var use 56 or 6 neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b692680a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:14.147582Z",
     "iopub.status.busy": "2024-11-12T05:59:14.147169Z",
     "iopub.status.idle": "2024-11-12T05:59:14.485029Z",
     "shell.execute_reply": "2024-11-12T05:59:14.483826Z"
    },
    "papermill": {
     "duration": 0.345754,
     "end_time": "2024-11-12T05:59:14.487652",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.141898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y, high_variance_columns = load(per=0.89, isVar=False) \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state= 4)\n",
    "X_train_rows = [row.to_numpy() for _, row in x.iterrows()]\n",
    "\n",
    "test_df_1 = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "\n",
    "test_ds_pd = test_df_1.drop('Id' ,axis=1)\n",
    "\n",
    "test_ds_pd['EJ'] = test_ds_pd['EJ'].map({'A': 0, 'B': 1})\n",
    "test_ds_pd.fillna(test_ds_pd.mean(), inplace=True)\n",
    "\n",
    "# avoid var\n",
    "test_ds_pd.drop(columns=high_variance_columns, inplace=True)\n",
    "\n",
    "X_test_rows = [row.to_numpy() for _, row in test_ds_pd.iterrows()]\n",
    "\n",
    "df = final_sub(101, X_train_rows, y, X_test_rows, test_df_1.Id)\n",
    "# df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed3ec21d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:14.497787Z",
     "iopub.status.busy": "2024-11-12T05:59:14.497388Z",
     "iopub.status.idle": "2024-11-12T05:59:14.510141Z",
     "shell.execute_reply": "2024-11-12T05:59:14.509059Z"
    },
    "papermill": {
     "duration": 0.020892,
     "end_time": "2024-11-12T05:59:14.512767",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.491875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "# K-Means function to assign clusters to class 0 or 1 based on training labels\n",
    "def kmeans_majority_label(train_data, train_labels, k, test_data):\n",
    "    # Convert train_data to a 2D array (each row as a training sample)\n",
    "    train_data = np.array(train_data)\n",
    "    test_data = np.array(test_data)\n",
    "    \n",
    "    # Fit K-Means on the training data\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0, n_init=10)\n",
    "    kmeans.fit(train_data)\n",
    "    \n",
    "    # Determine the majority label for each cluster\n",
    "    cluster_labels = np.zeros(k)\n",
    "    for cluster in range(k):\n",
    "        mask = kmeans.labels_ == cluster\n",
    "        # print(\"Xtrain\", train_data.shape)\n",
    "        if np.any(mask):  # Check if there are labels for this cluster\n",
    "            cluster_labels[cluster] = mode(train_labels[mask]).mode\n",
    "        else:\n",
    "            cluster_labels[cluster] = 0  # Default if cluster is empty\n",
    "    \n",
    "    # Predict the cluster for each test sample\n",
    "    test_clusters = kmeans.predict(test_data)\n",
    "    \n",
    "    # Map each test sample's cluster to the majority label of that cluster\n",
    "    predicted_labels = cluster_labels[test_clusters].astype(int)\n",
    "\n",
    "    return predicted_labels.tolist()\n",
    "\n",
    "# Calculate average probabilities across multiple K-Means models\n",
    "def getResult_kmeans(max_k, x_train, y_train, x_test):\n",
    "    arrays = [kmeans_majority_label(x_train, y_train, i, x_test) for i in range(2, max_k + 1)]  # K-Means for k values >= 2\n",
    "    return np.mean(np.stack(arrays), axis=0)  # Average across all models\n",
    "\n",
    "# Convert probabilities to class predictions (0 or 1) for K-Means\n",
    "def getClassesResult_kmeans(max_k, x_train, y_train, x_test):\n",
    "    return np.where(getResult_kmeans(max_k, x_train, y_train, x_test) >= 0.5, 1, 0)\n",
    "\n",
    "# Generate final DataFrame with probabilities for both classes for K-Means\n",
    "def final_sub_kmeans(max_k, x_train, y_train, x_test, ids):\n",
    "    class_1 = getResult_kmeans(max_k, x_train, y_train, x_test)\n",
    "    class_0 = 1 - class_1\n",
    "    return pd.DataFrame({'Id': ids, 'class_0': class_0, 'class_1': class_1})\n",
    "\n",
    "\n",
    "\n",
    "# This structure preserves the overall logic while adapting it to K-Means.\n",
    "# \"Code adaptation for K-Means clustering is complete.\"\n",
    "def percentage_equal(arr1, arr2):\n",
    "    return (np.sum(arr1 == arr2) / arr1.size) * 100\n",
    "print(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a39c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:14.523905Z",
     "iopub.status.busy": "2024-11-12T05:59:14.522726Z",
     "iopub.status.idle": "2024-11-12T05:59:14.534620Z",
     "shell.execute_reply": "2024-11-12T05:59:14.533752Z"
    },
    "papermill": {
     "duration": 0.019678,
     "end_time": "2024-11-12T05:59:14.536900",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.517222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracy_vs_i_1(train_df, test_df, message):\n",
    "    \"\"\"\n",
    "    Function to plot accuracy vs i values for different KNN models.\n",
    "\n",
    "    Parameters:\n",
    "    train_df (DataFrame): Training data features.\n",
    "    test_df (DataFrame): Test data features.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_df, test_df, test_size=0.2, random_state=4)\n",
    "    X_train_rows = [row.to_numpy() for _, row in X_train.iterrows()]\n",
    "    X_test_rows = [row.to_numpy() for _, row in X_test.iterrows()]\n",
    "\n",
    "    # Initialize lists for storing i values and accuracies\n",
    "    i_values, accuracies = [], []\n",
    "    # Loop through odd values of i\n",
    "    for i in range(3, 21,1):\n",
    "        if i % 5 == 0:\n",
    "            print(\"i is _\", i)\n",
    "        y_pred = getClassesResult_kmeans(i, X_train_rows, y_train, X_test_rows)\n",
    "        accuracy = percentage_equal(y_pred, y_test)\n",
    "        i_values.append(i)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    j , acc = i_values[np.argmax(accuracies)], np.max(accuracies)\n",
    "    # Plot the results\n",
    "    # plt.plot(i_values, accuracies, linestyle='-', color='b')\n",
    "    # plt.xlabel('i values')\n",
    "    # plt.ylabel('Test Accuracy')\n",
    "    # plt.title('Accuracy vs i')\n",
    "    # plt.grid(True)\n",
    "    # plt.show()\n",
    "    print(f\"{message} Best i is: {j} with acc of: {acc:.3f}\")\n",
    "    return j , acc\n",
    "\n",
    "def run_diff_var_1():\n",
    "    def run(isVar, mes):\n",
    "        i_values, accuracies = [], []\n",
    "        for i in np.arange(0.05, 1, 0.05):\n",
    "            percentage = round(i * 100, 3)\n",
    "            message_with_percent = f\"{mes} at {percentage}% varianced columns\"\n",
    "            # Call your load function with the appropriate parameters\n",
    "            x, y, _ = load(per=i, isVar=isVar)  \n",
    "            j,accuracy = plot_accuracy_vs_i_1(x, y, message_with_percent)\n",
    "            i_values.append((i,j))\n",
    "            accuracies.append(accuracy)\n",
    "        print(f\"Best (per, K) is: {i_values[np.argmax(accuracies)]} with acc of: {np.max(accuracies):.3f}\")\n",
    "\n",
    "    run(True, \"Using variance    \")  # Message when variance is used\n",
    "    run(False, \"Not using variance\")  # Message when variance is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e5bd011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-12T05:59:14.547315Z",
     "iopub.status.busy": "2024-11-12T05:59:14.546884Z",
     "iopub.status.idle": "2024-11-12T05:59:14.697161Z",
     "shell.execute_reply": "2024-11-12T05:59:14.695942Z"
    },
    "papermill": {
     "duration": 0.158534,
     "end_time": "2024-11-12T05:59:14.699809",
     "exception": false,
     "start_time": "2024-11-12T05:59:14.541275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x, y, high_variance_columns = load(per=0.2, isVar=False) \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state= 4)\n",
    "X_train_rows = [row.to_numpy() for _, row in x.iterrows()]\n",
    "\n",
    "test_df_1 = pd.read_csv('/kaggle/input/icr-identify-age-related-conditions/test.csv')\n",
    "\n",
    "test_ds_pd = test_df_1.drop('Id' ,axis=1)\n",
    "\n",
    "test_ds_pd['EJ'] = test_ds_pd['EJ'].map({'A': 0, 'B': 1})\n",
    "test_ds_pd.fillna(test_ds_pd.mean(), inplace=True)\n",
    "\n",
    "# avoid var\n",
    "test_ds_pd.drop(columns=high_variance_columns, inplace=True)\n",
    "\n",
    "X_test_rows = [row.to_numpy() for _, row in test_ds_pd.iterrows()]\n",
    "\n",
    "df = final_sub(11, X_train_rows, y, X_test_rows, test_df_1.Id)\n",
    "df.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 5687476,
     "sourceId": 52784,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.431055,
   "end_time": "2024-11-12T05:59:16.229198",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-12T05:58:53.798143",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
